{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization as BNOR\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from Teemo.datasets.loaders.mnist_loader import MnistLoader\n",
    "from Teemo.datasets.base import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg16(input_placeholder):\n",
    "    h = Conv2D(64, (3, 3), activation='relu', strides=1, padding='same', name='block1_conv1')(input_placeholder)\n",
    "    h = Conv2D(64, (3, 3), activation='relu', strides=1, padding='same', name='block1_conv2')(h)\n",
    "    h = MaxPooling2D( pool_size=(2,2),strides=(2,2),name='block1_pool' )(h)\n",
    "    print ('block 1')\n",
    "# block 2\n",
    "    h = Conv2D(128, (3, 3), activation='relu', strides=1, padding='same', name='block2_conv1')(h)\n",
    "    h = Conv2D(128, (3, 3), activation='relu', strides=1, padding='same', name='block2_conv2')(h)\n",
    "    h = MaxPooling2D( pool_size=(2,2),strides=(2,2),name='block2_pool')(h)\n",
    "# # block 3\n",
    "#     h = Conv2D(256, (3, 3), activation='relu', strides=1, padding='same', name='block3_conv1')(h)\n",
    "#     h = Conv2D(256, (3, 3), activation='relu', strides=1, padding='same', name='block3_conv2')(h)\n",
    "#     h = Conv2D(256, (3, 3), activation='relu', strides=1, padding='same', name='block3_conv3')(h)\n",
    "#     h = MaxPooling2D( pool_size=(2,2),strides=(2,2),name='block3_pool')(h)\n",
    "# # block 4\n",
    "#     h = Conv2D(512, (3, 3), activation='relu', strides=1, padding='same', name='block4_conv1')(h)\n",
    "#     h = Conv2D(512, (3, 3), activation='relu', strides=1, padding='same', name='block4_conv2')(h)\n",
    "#     h = Conv2D(512, (3, 3), activation='relu', strides=1, padding='same', name='block4_conv3')(h)\n",
    "#     h = MaxPooling2D( pool_size=(2,2),strides=(2,2),name='block4_pool' )(h)\n",
    "#     print ('h', h)\n",
    "# block 5\n",
    "#     h = Conv2D(512, (3, 3), activation='relu', strides=1, padding='same', name='block5_conv1')(h)\n",
    "#     h = Conv2D(512, (3, 3), activation='relu', strides=1, padding='same', name='block5_conv2')(h)\n",
    "#     h = Conv2D(512, (3, 3), activation='relu', strides=1, padding='same', name='block5_conv3')(h)\n",
    "#     print ('block 5')\n",
    "#     print ('h', h)\n",
    "    #h = MaxPooling2D( pool_size=(2,2),strides=(2,2),name='block5_pool' )(h)\n",
    "\t#model.load_weights('~/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/home/liyuanpeng/Documents/minist'\n",
    "loader = MnistLoader()\n",
    "loader.load_dataset(dataset_dir)\n",
    "dataset = Dataset(loader=loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 28, 28, 1)\n",
      "(70000,)\n",
      "block 1\n",
      "Tensor(\"flatten_1/Reshape:0\", shape=(?, ?), dtype=float32)\n",
      "Train on 63000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "63000/63000 [==============================] - 611s - loss: 0.1405 - acc: 0.9555 - val_loss: 0.0258 - val_acc: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f201cd62850>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_x = dataset.data[0]\n",
    "input_x = input_x.reshape([-1, 28, 28, 1])\n",
    "label = dataset.labels[0]\n",
    "\n",
    "x = Input(shape=(28, 28, 1))\n",
    "output = vgg16(x)\n",
    "# output = tf.reshape(output, [-1, 512])\n",
    "output = Flatten(name='flatten_1')(output)\n",
    "print (output)\n",
    "h = Dense(100, activation='relu')(output)\n",
    "predict = Dense(10, activation='softmax')(h)\n",
    "model = Model(x, predict)\n",
    "model.compile(optimizer='Adam',\n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "model.fit(input_x, label, validation_split=0.1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}